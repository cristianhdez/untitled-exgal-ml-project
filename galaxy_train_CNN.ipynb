{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from modules import datasets\n",
    "from modules import models\n",
    "\n",
    "from keras.backend import set_epsilon\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading halo attributes...\n",
      "[INFO] constructing training/testing split...\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-d\", \"--dataset\", type=str, required=True,\n",
    "#    help=\"path to input dataset of house images\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "##SAG3.csv has 10000 samples and no galaxies with 0 mass\n",
    "##SAG4.csv has 10000 samples and no restrictions on mass\n",
    "##SAG5.csv has 15000 samples and no restrictions on mass\n",
    "##SAG6.csv has 10000 samples and masses over 10e+7 solar masses\n",
    "inputPath = 'SAG3.csv'\n",
    "\n",
    "\n",
    "# construct the path to the input .txt file that contains information\n",
    "# on each house in the dataset and then load the dataset\n",
    "print(\"[INFO] loading halo attributes...\")\n",
    "#inputPath = os.path.sep.join([args[\"dataset\"], \"HousesInfo.txt\"])\n",
    "df = datasets.load_halo_attributes(inputPath)\n",
    " \n",
    "# construct a training and testing split with 75% of the data used\n",
    "# for training and the remaining 25% for evaluation\n",
    "print(\"[INFO] constructing training/testing split...\")\n",
    "(train, test) = train_test_split(df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1222.,  108.,   53.,   46.,   22.,   12.,   13.,   10.,   12.,\n",
       "           5.]),\n",
       " array([1.00e+08, 1.09e+09, 2.08e+09, 3.07e+09, 4.06e+09, 5.05e+09,\n",
       "        6.04e+09, 7.03e+09, 8.02e+09, 9.01e+09, 1.00e+10]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##replacing zeroes for very low masses so log10 doesn't fail\n",
    "##trying with sum of masses\n",
    "\n",
    "dummy_train = train['MstarDisk'] + train['MstarSpheroid']\n",
    "#dummy_train = np.where(dummy_train==0, 1e-10, dummy_train)\n",
    "\n",
    "dummy_test = test['MstarDisk'] + test['MstarSpheroid']\n",
    "#dummy_test = np.where(dummy_test==0, 1e-10, dummy_test)\n",
    "print(np.min(dummy_train))\n",
    "plt.hist(dummy_train, range=[10e7, 10e9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def log10bins(col, n=10):\n",
    "    x=np.log10(np.array(col))\n",
    "    bins = []\n",
    "    percs = [-11]\n",
    "    for i in range(n):\n",
    "        percs.append(np.percentile(x, (i+1)*100/n))\n",
    "    for item in x:\n",
    "\n",
    "        for i in range(n):\n",
    "            if item > percs[i] and item <= percs[i+1]:\n",
    "                bins.append(i)\n",
    "\n",
    "    return np.array(bins)\n",
    "\n",
    "\n",
    "plt.hist(log10bins(dummy_train))    \n",
    "train_Y = log10bins(dummy_train)\n",
    "test_Y = log10bins(dummy_test)\n",
    "print(len(train_Y))\n",
    "#These 2 commented lines checked if the percentiles were distributed correctly\n",
    "#unique, counts = np.unique(log10bins(test['MstarDisk']), return_counts=True)\n",
    "#dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "trainY = to_categorical(train_Y, num_classes=None)\n",
    "testY = to_categorical(test_Y, num_classes=None)\n",
    "\n",
    "print (np.shape(trainY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing data...\n",
      "(7500, 4, 1)\n",
      "(2500, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[INFO] processing data...\")\n",
    "(trainX, testX) = datasets.process_halo_attributes(df, train, test)\n",
    "\n",
    "trainX = np.expand_dims(trainX, axis=2) ##Adding third dimension to input data so conv1D can be applied\n",
    "testX = np.expand_dims(testX, axis=2)\n",
    "print(np.shape(trainX))\n",
    "print(np.shape(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/200\n",
      "7500/7500 [==============================] - 2s 314us/step - loss: 2.2145 - accuracy: 0.1655 - recall: 0.0041 - val_loss: 2.1595 - val_accuracy: 0.1752 - val_recall: 0.0122\n",
      "Epoch 2/200\n",
      "7500/7500 [==============================] - 1s 168us/step - loss: 2.1309 - accuracy: 0.1859 - recall: 0.0159 - val_loss: 2.1410 - val_accuracy: 0.1760 - val_recall: 0.0182\n",
      "Epoch 3/200\n",
      "7500/7500 [==============================] - 1s 177us/step - loss: 2.1215 - accuracy: 0.1885 - recall: 0.0193 - val_loss: 2.1318 - val_accuracy: 0.1948 - val_recall: 0.0202\n",
      "Epoch 4/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 2.1135 - accuracy: 0.1931 - recall: 0.0208 - val_loss: 2.1289 - val_accuracy: 0.1988 - val_recall: 0.0215\n",
      "Epoch 5/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 2.1088 - accuracy: 0.2044 - recall: 0.0219 - val_loss: 2.1216 - val_accuracy: 0.1932 - val_recall: 0.0223\n",
      "Epoch 6/200\n",
      "7500/7500 [==============================] - 1s 166us/step - loss: 2.1054 - accuracy: 0.1997 - recall: 0.0227 - val_loss: 2.1150 - val_accuracy: 0.1924 - val_recall: 0.0228\n",
      "Epoch 7/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 2.1004 - accuracy: 0.2009 - recall: 0.0229 - val_loss: 2.1107 - val_accuracy: 0.1988 - val_recall: 0.0229\n",
      "Epoch 8/200\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 2.0875 - accuracy: 0.2080 - recall: 0.0230 - val_loss: 2.0954 - val_accuracy: 0.2032 - val_recall: 0.0233\n",
      "Epoch 9/200\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 2.0742 - accuracy: 0.2149 - recall: 0.0235 - val_loss: 2.0682 - val_accuracy: 0.2352 - val_recall: 0.0241\n",
      "Epoch 10/200\n",
      "7500/7500 [==============================] - 1s 180us/step - loss: 2.0473 - accuracy: 0.2253 - recall: 0.0246 - val_loss: 2.0417 - val_accuracy: 0.2696 - val_recall: 0.0250\n",
      "Epoch 11/200\n",
      "7500/7500 [==============================] - 1s 188us/step - loss: 2.0191 - accuracy: 0.2403 - recall: 0.0255 - val_loss: 1.9859 - val_accuracy: 0.2752 - val_recall: 0.0262\n",
      "Epoch 12/200\n",
      "7500/7500 [==============================] - 1s 189us/step - loss: 1.9855 - accuracy: 0.2527 - recall: 0.0269 - val_loss: 1.9498 - val_accuracy: 0.2684 - val_recall: 0.0277\n",
      "Epoch 13/200\n",
      "7500/7500 [==============================] - 1s 198us/step - loss: 1.9475 - accuracy: 0.2604 - recall: 0.0284 - val_loss: 1.8977 - val_accuracy: 0.3068 - val_recall: 0.0292\n",
      "Epoch 14/200\n",
      "7500/7500 [==============================] - 1s 190us/step - loss: 1.9078 - accuracy: 0.2813 - recall: 0.0301 - val_loss: 1.8504 - val_accuracy: 0.2956 - val_recall: 0.0310\n",
      "Epoch 15/200\n",
      "7500/7500 [==============================] - 1s 180us/step - loss: 1.8791 - accuracy: 0.2835 - recall: 0.0319 - val_loss: 1.8292 - val_accuracy: 0.3044 - val_recall: 0.0326\n",
      "Epoch 16/200\n",
      "7500/7500 [==============================] - 1s 190us/step - loss: 1.8405 - accuracy: 0.2945 - recall: 0.0332 - val_loss: 1.7859 - val_accuracy: 0.3100 - val_recall: 0.0340\n",
      "Epoch 17/200\n",
      "7500/7500 [==============================] - 1s 186us/step - loss: 1.8307 - accuracy: 0.3023 - recall: 0.0347 - val_loss: 1.7445 - val_accuracy: 0.3480 - val_recall: 0.0353\n",
      "Epoch 18/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.8012 - accuracy: 0.3035 - recall: 0.0359 - val_loss: 1.7278 - val_accuracy: 0.3044 - val_recall: 0.0367\n",
      "Epoch 19/200\n",
      "7500/7500 [==============================] - 1s 176us/step - loss: 1.7751 - accuracy: 0.3044 - recall: 0.0374 - val_loss: 1.6884 - val_accuracy: 0.3492 - val_recall: 0.0381\n",
      "Epoch 20/200\n",
      "7500/7500 [==============================] - 2s 203us/step - loss: 1.7707 - accuracy: 0.3143 - recall: 0.0388 - val_loss: 1.6908 - val_accuracy: 0.3216 - val_recall: 0.0393\n",
      "Epoch 21/200\n",
      "7500/7500 [==============================] - 1s 196us/step - loss: 1.7483 - accuracy: 0.3168 - recall: 0.0398 - val_loss: 1.6693 - val_accuracy: 0.3416 - val_recall: 0.0405\n",
      "Epoch 22/200\n",
      "7500/7500 [==============================] - 1s 189us/step - loss: 1.7344 - accuracy: 0.3176 - recall: 0.0410 - val_loss: 1.6256 - val_accuracy: 0.3568 - val_recall: 0.0415\n",
      "Epoch 23/200\n",
      "7500/7500 [==============================] - 1s 184us/step - loss: 1.7047 - accuracy: 0.3257 - recall: 0.0422 - val_loss: 1.6188 - val_accuracy: 0.3608 - val_recall: 0.0428\n",
      "Epoch 24/200\n",
      "7500/7500 [==============================] - 1s 181us/step - loss: 1.7062 - accuracy: 0.3307 - recall: 0.0434 - val_loss: 1.6302 - val_accuracy: 0.3640 - val_recall: 0.0438\n",
      "Epoch 25/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.6989 - accuracy: 0.3312 - recall: 0.0442 - val_loss: 1.6008 - val_accuracy: 0.3700 - val_recall: 0.0448\n",
      "Epoch 26/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.6871 - accuracy: 0.3291 - recall: 0.0454 - val_loss: 1.5807 - val_accuracy: 0.3636 - val_recall: 0.0460\n",
      "Epoch 27/200\n",
      "7500/7500 [==============================] - 1s 159us/step - loss: 1.6694 - accuracy: 0.3325 - recall: 0.0467 - val_loss: 1.5902 - val_accuracy: 0.3732 - val_recall: 0.0472\n",
      "Epoch 28/200\n",
      "7500/7500 [==============================] - 1s 159us/step - loss: 1.6756 - accuracy: 0.3451 - recall: 0.0477 - val_loss: 1.5791 - val_accuracy: 0.3664 - val_recall: 0.0483\n",
      "Epoch 29/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.6667 - accuracy: 0.3335 - recall: 0.0488 - val_loss: 1.6045 - val_accuracy: 0.3640 - val_recall: 0.0493\n",
      "Epoch 30/200\n",
      "7500/7500 [==============================] - 1s 182us/step - loss: 1.6533 - accuracy: 0.3448 - recall: 0.0497 - val_loss: 1.5758 - val_accuracy: 0.3648 - val_recall: 0.0501\n",
      "Epoch 31/200\n",
      "7500/7500 [==============================] - 1s 181us/step - loss: 1.6595 - accuracy: 0.3444 - recall: 0.0505 - val_loss: 1.5836 - val_accuracy: 0.3656 - val_recall: 0.0510\n",
      "Epoch 32/200\n",
      "7500/7500 [==============================] - 1s 178us/step - loss: 1.6496 - accuracy: 0.3505 - recall: 0.0515 - val_loss: 1.5711 - val_accuracy: 0.3644 - val_recall: 0.0522\n",
      "Epoch 33/200\n",
      "7500/7500 [==============================] - 1s 180us/step - loss: 1.6517 - accuracy: 0.3425 - recall: 0.0528 - val_loss: 1.5515 - val_accuracy: 0.3740 - val_recall: 0.0533\n",
      "Epoch 34/200\n",
      "7500/7500 [==============================] - 1s 156us/step - loss: 1.6460 - accuracy: 0.3368 - recall: 0.0536 - val_loss: 1.5542 - val_accuracy: 0.3736 - val_recall: 0.0542\n",
      "Epoch 35/200\n",
      "7500/7500 [==============================] - 1s 156us/step - loss: 1.6515 - accuracy: 0.3404 - recall: 0.0547 - val_loss: 1.5624 - val_accuracy: 0.3640 - val_recall: 0.0552\n",
      "Epoch 36/200\n",
      "7500/7500 [==============================] - 1s 156us/step - loss: 1.6393 - accuracy: 0.3511 - recall: 0.0557 - val_loss: 1.5867 - val_accuracy: 0.3344 - val_recall: 0.0562\n",
      "Epoch 37/200\n",
      "7500/7500 [==============================] - 1s 157us/step - loss: 1.6290 - accuracy: 0.3492 - recall: 0.0566 - val_loss: 1.5729 - val_accuracy: 0.3672 - val_recall: 0.0572\n",
      "Epoch 38/200\n",
      "7500/7500 [==============================] - 1s 156us/step - loss: 1.6299 - accuracy: 0.3496 - recall: 0.0577 - val_loss: 1.5674 - val_accuracy: 0.3620 - val_recall: 0.0582\n",
      "Epoch 39/200\n",
      "7500/7500 [==============================] - 1s 154us/step - loss: 1.6310 - accuracy: 0.3495 - recall: 0.0586 - val_loss: 1.5376 - val_accuracy: 0.3652 - val_recall: 0.0590\n",
      "Epoch 40/200\n",
      "7500/7500 [==============================] - 1s 156us/step - loss: 1.6291 - accuracy: 0.3499 - recall: 0.0594 - val_loss: 1.5605 - val_accuracy: 0.3752 - val_recall: 0.0598\n",
      "Epoch 41/200\n",
      "7500/7500 [==============================] - 1s 160us/step - loss: 1.6343 - accuracy: 0.3464 - recall: 0.0601 - val_loss: 1.5870 - val_accuracy: 0.3440 - val_recall: 0.0605\n",
      "Epoch 42/200\n",
      "7500/7500 [==============================] - 1s 155us/step - loss: 1.6332 - accuracy: 0.3495 - recall: 0.0609 - val_loss: 1.5472 - val_accuracy: 0.3872 - val_recall: 0.0612\n",
      "Epoch 43/200\n",
      "7500/7500 [==============================] - 1s 157us/step - loss: 1.6313 - accuracy: 0.3520 - recall: 0.0615 - val_loss: 1.5465 - val_accuracy: 0.3820 - val_recall: 0.0618\n",
      "Epoch 44/200\n",
      "7500/7500 [==============================] - 1s 155us/step - loss: 1.6254 - accuracy: 0.3580 - recall: 0.0621 - val_loss: 1.5574 - val_accuracy: 0.3708 - val_recall: 0.0626\n",
      "Epoch 45/200\n",
      "7500/7500 [==============================] - 1s 155us/step - loss: 1.6200 - accuracy: 0.3533 - recall: 0.0630 - val_loss: 1.5540 - val_accuracy: 0.3724 - val_recall: 0.0634\n",
      "Epoch 46/200\n",
      "7500/7500 [==============================] - 1s 157us/step - loss: 1.6126 - accuracy: 0.3591 - recall: 0.0638 - val_loss: 1.5407 - val_accuracy: 0.3888 - val_recall: 0.0641\n",
      "Epoch 47/200\n",
      "7500/7500 [==============================] - 1s 157us/step - loss: 1.6178 - accuracy: 0.3532 - recall: 0.0643 - val_loss: 1.5306 - val_accuracy: 0.3776 - val_recall: 0.0647\n",
      "Epoch 48/200\n",
      "7500/7500 [==============================] - 1s 190us/step - loss: 1.6113 - accuracy: 0.3595 - recall: 0.0650 - val_loss: 1.5268 - val_accuracy: 0.3856 - val_recall: 0.0654\n",
      "Epoch 49/200\n",
      "7500/7500 [==============================] - 1s 192us/step - loss: 1.6146 - accuracy: 0.3545 - recall: 0.0658 - val_loss: 1.5244 - val_accuracy: 0.3904 - val_recall: 0.0660\n",
      "Epoch 50/200\n",
      "7500/7500 [==============================] - 1s 192us/step - loss: 1.6042 - accuracy: 0.3560 - recall: 0.0663 - val_loss: 1.5548 - val_accuracy: 0.3744 - val_recall: 0.0666\n",
      "Epoch 51/200\n",
      "7500/7500 [==============================] - 1s 190us/step - loss: 1.6239 - accuracy: 0.3519 - recall: 0.0669 - val_loss: 1.5489 - val_accuracy: 0.3748 - val_recall: 0.0671\n",
      "Epoch 52/200\n",
      "7500/7500 [==============================] - 1s 187us/step - loss: 1.6125 - accuracy: 0.3556 - recall: 0.0673 - val_loss: 1.5252 - val_accuracy: 0.3948 - val_recall: 0.0676\n",
      "Epoch 53/200\n",
      "7500/7500 [==============================] - 2s 201us/step - loss: 1.6202 - accuracy: 0.3495 - recall: 0.0680 - val_loss: 1.5481 - val_accuracy: 0.3688 - val_recall: 0.0682\n",
      "Epoch 54/200\n",
      "7500/7500 [==============================] - 1s 198us/step - loss: 1.6094 - accuracy: 0.3617 - recall: 0.0684 - val_loss: 1.5219 - val_accuracy: 0.3784 - val_recall: 0.0687\n",
      "Epoch 55/200\n",
      "7500/7500 [==============================] - 1s 188us/step - loss: 1.6076 - accuracy: 0.3591 - recall: 0.0690 - val_loss: 1.5395 - val_accuracy: 0.3696 - val_recall: 0.0693\n",
      "Epoch 56/200\n",
      "7500/7500 [==============================] - 1s 185us/step - loss: 1.6057 - accuracy: 0.3519 - recall: 0.0695 - val_loss: 1.5531 - val_accuracy: 0.3864 - val_recall: 0.0697\n",
      "Epoch 57/200\n",
      "7500/7500 [==============================] - 2s 203us/step - loss: 1.6116 - accuracy: 0.3555 - recall: 0.0700 - val_loss: 1.5308 - val_accuracy: 0.3912 - val_recall: 0.0702\n",
      "Epoch 58/200\n",
      "7500/7500 [==============================] - 1s 189us/step - loss: 1.6046 - accuracy: 0.3535 - recall: 0.0703 - val_loss: 1.5150 - val_accuracy: 0.3860 - val_recall: 0.0706\n",
      "Epoch 59/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5954 - accuracy: 0.3621 - recall: 0.0709 - val_loss: 1.5250 - val_accuracy: 0.3816 - val_recall: 0.0711\n",
      "Epoch 60/200\n",
      "7500/7500 [==============================] - 1s 168us/step - loss: 1.6078 - accuracy: 0.3559 - recall: 0.0713 - val_loss: 1.5431 - val_accuracy: 0.3764 - val_recall: 0.0714\n",
      "Epoch 61/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.6010 - accuracy: 0.3545 - recall: 0.0716 - val_loss: 1.5394 - val_accuracy: 0.3896 - val_recall: 0.0718\n",
      "Epoch 62/200\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 1.5986 - accuracy: 0.3519 - recall: 0.0719 - val_loss: 1.4864 - val_accuracy: 0.4076 - val_recall: 0.0722\n",
      "Epoch 63/200\n",
      "7500/7500 [==============================] - 1s 185us/step - loss: 1.6095 - accuracy: 0.3513 - recall: 0.0724 - val_loss: 1.5463 - val_accuracy: 0.3852 - val_recall: 0.0726\n",
      "Epoch 64/200\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.5992 - accuracy: 0.3587 - recall: 0.0728 - val_loss: 1.5214 - val_accuracy: 0.3988 - val_recall: 0.0730\n",
      "Epoch 65/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.6014 - accuracy: 0.3545 - recall: 0.0731 - val_loss: 1.5052 - val_accuracy: 0.3968 - val_recall: 0.0733\n",
      "Epoch 66/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5986 - accuracy: 0.3657 - recall: 0.0736 - val_loss: 1.4918 - val_accuracy: 0.3900 - val_recall: 0.0738\n",
      "Epoch 67/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5912 - accuracy: 0.3615 - recall: 0.0740 - val_loss: 1.5208 - val_accuracy: 0.3888 - val_recall: 0.0742\n",
      "Epoch 68/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5890 - accuracy: 0.3692 - recall: 0.0744 - val_loss: 1.5155 - val_accuracy: 0.3916 - val_recall: 0.0746\n",
      "Epoch 69/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.6026 - accuracy: 0.3584 - recall: 0.0748 - val_loss: 1.4926 - val_accuracy: 0.3912 - val_recall: 0.0750\n",
      "Epoch 70/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5929 - accuracy: 0.3635 - recall: 0.0752 - val_loss: 1.5582 - val_accuracy: 0.3688 - val_recall: 0.0755\n",
      "Epoch 71/200\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 1.5933 - accuracy: 0.3675 - recall: 0.0757 - val_loss: 1.5002 - val_accuracy: 0.4044 - val_recall: 0.0759\n",
      "Epoch 72/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5850 - accuracy: 0.3697 - recall: 0.0760 - val_loss: 1.5250 - val_accuracy: 0.3908 - val_recall: 0.0762\n",
      "Epoch 73/200\n",
      "7500/7500 [==============================] - 1s 177us/step - loss: 1.5962 - accuracy: 0.3613 - recall: 0.0765 - val_loss: 1.5391 - val_accuracy: 0.3812 - val_recall: 0.0766\n",
      "Epoch 74/200\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 1.6022 - accuracy: 0.3617 - recall: 0.0767 - val_loss: 1.5172 - val_accuracy: 0.4016 - val_recall: 0.0770\n",
      "Epoch 75/200\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 1.6014 - accuracy: 0.3627 - recall: 0.0772 - val_loss: 1.4863 - val_accuracy: 0.4052 - val_recall: 0.0774\n",
      "Epoch 76/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.6028 - accuracy: 0.3624 - recall: 0.0776 - val_loss: 1.5321 - val_accuracy: 0.4016 - val_recall: 0.0778\n",
      "Epoch 77/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5903 - accuracy: 0.3593 - recall: 0.0779 - val_loss: 1.5181 - val_accuracy: 0.3908 - val_recall: 0.0780\n",
      "Epoch 78/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5938 - accuracy: 0.3757 - recall: 0.0782 - val_loss: 1.5086 - val_accuracy: 0.3868 - val_recall: 0.0784\n",
      "Epoch 79/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5949 - accuracy: 0.3683 - recall: 0.0785 - val_loss: 1.4913 - val_accuracy: 0.4144 - val_recall: 0.0786\n",
      "Epoch 80/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5881 - accuracy: 0.3675 - recall: 0.0787 - val_loss: 1.5102 - val_accuracy: 0.3976 - val_recall: 0.0789\n",
      "Epoch 81/200\n",
      "7500/7500 [==============================] - 1s 176us/step - loss: 1.5780 - accuracy: 0.3665 - recall: 0.0792 - val_loss: 1.4759 - val_accuracy: 0.4140 - val_recall: 0.0793\n",
      "Epoch 82/200\n",
      "7500/7500 [==============================] - 1s 168us/step - loss: 1.5952 - accuracy: 0.3588 - recall: 0.0794 - val_loss: 1.4977 - val_accuracy: 0.3968 - val_recall: 0.0796\n",
      "Epoch 83/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5934 - accuracy: 0.3676 - recall: 0.0797 - val_loss: 1.4931 - val_accuracy: 0.4112 - val_recall: 0.0799\n",
      "Epoch 84/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5981 - accuracy: 0.3693 - recall: 0.0801 - val_loss: 1.4955 - val_accuracy: 0.4080 - val_recall: 0.0802\n",
      "Epoch 85/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5915 - accuracy: 0.3727 - recall: 0.0803 - val_loss: 1.5088 - val_accuracy: 0.4004 - val_recall: 0.0804\n",
      "Epoch 86/200\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.5887 - accuracy: 0.3645 - recall: 0.0805 - val_loss: 1.5113 - val_accuracy: 0.3936 - val_recall: 0.0806\n",
      "Epoch 87/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5783 - accuracy: 0.3727 - recall: 0.0808 - val_loss: 1.5135 - val_accuracy: 0.3988 - val_recall: 0.0809\n",
      "Epoch 88/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5767 - accuracy: 0.3683 - recall: 0.0811 - val_loss: 1.4964 - val_accuracy: 0.3808 - val_recall: 0.0812\n",
      "Epoch 89/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5883 - accuracy: 0.3715 - recall: 0.0813 - val_loss: 1.5345 - val_accuracy: 0.3816 - val_recall: 0.0814\n",
      "Epoch 90/200\n",
      "7500/7500 [==============================] - 1s 179us/step - loss: 1.5765 - accuracy: 0.3673 - recall: 0.0815 - val_loss: 1.4724 - val_accuracy: 0.4084 - val_recall: 0.0816\n",
      "Epoch 91/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5803 - accuracy: 0.3648 - recall: 0.0818 - val_loss: 1.4816 - val_accuracy: 0.4064 - val_recall: 0.0819\n",
      "Epoch 92/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5921 - accuracy: 0.3671 - recall: 0.0820 - val_loss: 1.4913 - val_accuracy: 0.4028 - val_recall: 0.0821\n",
      "Epoch 93/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5740 - accuracy: 0.3728 - recall: 0.0823 - val_loss: 1.5498 - val_accuracy: 0.3900 - val_recall: 0.0823\n",
      "Epoch 94/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5786 - accuracy: 0.3719 - recall: 0.0824 - val_loss: 1.4822 - val_accuracy: 0.4092 - val_recall: 0.0826\n",
      "Epoch 95/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5649 - accuracy: 0.3808 - recall: 0.0828 - val_loss: 1.4873 - val_accuracy: 0.4028 - val_recall: 0.0830\n",
      "Epoch 96/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5865 - accuracy: 0.3711 - recall: 0.0831 - val_loss: 1.5027 - val_accuracy: 0.4080 - val_recall: 0.0833\n",
      "Epoch 97/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5782 - accuracy: 0.3664 - recall: 0.0834 - val_loss: 1.4717 - val_accuracy: 0.4184 - val_recall: 0.0835\n",
      "Epoch 98/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5790 - accuracy: 0.3723 - recall: 0.0836 - val_loss: 1.4936 - val_accuracy: 0.3924 - val_recall: 0.0837\n",
      "Epoch 99/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5858 - accuracy: 0.3712 - recall: 0.0838 - val_loss: 1.4895 - val_accuracy: 0.4088 - val_recall: 0.0839\n",
      "Epoch 100/200\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.5712 - accuracy: 0.3748 - recall: 0.0840 - val_loss: 1.4841 - val_accuracy: 0.3980 - val_recall: 0.0841\n",
      "Epoch 101/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5893 - accuracy: 0.3683 - recall: 0.0842 - val_loss: 1.4960 - val_accuracy: 0.4020 - val_recall: 0.0843\n",
      "Epoch 102/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5925 - accuracy: 0.3676 - recall: 0.0843 - val_loss: 1.4847 - val_accuracy: 0.4024 - val_recall: 0.0845\n",
      "Epoch 103/200\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 1.5726 - accuracy: 0.3735 - recall: 0.0846 - val_loss: 1.4531 - val_accuracy: 0.4280 - val_recall: 0.0847\n",
      "Epoch 104/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5804 - accuracy: 0.3680 - recall: 0.0848 - val_loss: 1.4799 - val_accuracy: 0.4156 - val_recall: 0.0850\n",
      "Epoch 105/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5795 - accuracy: 0.3691 - recall: 0.0851 - val_loss: 1.4746 - val_accuracy: 0.4092 - val_recall: 0.0852\n",
      "Epoch 106/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5876 - accuracy: 0.3719 - recall: 0.0853 - val_loss: 1.4958 - val_accuracy: 0.4248 - val_recall: 0.0853\n",
      "Epoch 107/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5772 - accuracy: 0.3735 - recall: 0.0854 - val_loss: 1.4825 - val_accuracy: 0.4128 - val_recall: 0.0855\n",
      "Epoch 108/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5889 - accuracy: 0.3720 - recall: 0.0856 - val_loss: 1.4582 - val_accuracy: 0.4212 - val_recall: 0.0857\n",
      "Epoch 109/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5825 - accuracy: 0.3703 - recall: 0.0858 - val_loss: 1.4961 - val_accuracy: 0.4120 - val_recall: 0.0858\n",
      "Epoch 110/200\n",
      "7500/7500 [==============================] - 1s 168us/step - loss: 1.5797 - accuracy: 0.3717 - recall: 0.0859 - val_loss: 1.5043 - val_accuracy: 0.3956 - val_recall: 0.0860\n",
      "Epoch 111/200\n",
      "7500/7500 [==============================] - 1s 177us/step - loss: 1.5779 - accuracy: 0.3741 - recall: 0.0861 - val_loss: 1.5075 - val_accuracy: 0.3896 - val_recall: 0.0862\n",
      "Epoch 112/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5818 - accuracy: 0.3729 - recall: 0.0863 - val_loss: 1.4998 - val_accuracy: 0.4160 - val_recall: 0.0864\n",
      "Epoch 113/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5856 - accuracy: 0.3699 - recall: 0.0864 - val_loss: 1.4872 - val_accuracy: 0.4104 - val_recall: 0.0865\n",
      "Epoch 114/200\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.5695 - accuracy: 0.3743 - recall: 0.0865 - val_loss: 1.4767 - val_accuracy: 0.4200 - val_recall: 0.0866\n",
      "Epoch 115/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5701 - accuracy: 0.3747 - recall: 0.0867 - val_loss: 1.4717 - val_accuracy: 0.4164 - val_recall: 0.0868\n",
      "Epoch 116/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5773 - accuracy: 0.3684 - recall: 0.0868 - val_loss: 1.4943 - val_accuracy: 0.4176 - val_recall: 0.0869\n",
      "Epoch 117/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5787 - accuracy: 0.3756 - recall: 0.0870 - val_loss: 1.4641 - val_accuracy: 0.4180 - val_recall: 0.0871\n",
      "Epoch 118/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5717 - accuracy: 0.3729 - recall: 0.0871 - val_loss: 1.4716 - val_accuracy: 0.4104 - val_recall: 0.0872\n",
      "Epoch 119/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5767 - accuracy: 0.3696 - recall: 0.0873 - val_loss: 1.4742 - val_accuracy: 0.4028 - val_recall: 0.0874\n",
      "Epoch 120/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5817 - accuracy: 0.3665 - recall: 0.0875 - val_loss: 1.4906 - val_accuracy: 0.4148 - val_recall: 0.0875\n",
      "Epoch 121/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5748 - accuracy: 0.3649 - recall: 0.0876 - val_loss: 1.4656 - val_accuracy: 0.4160 - val_recall: 0.0877\n",
      "Epoch 122/200\n",
      "7500/7500 [==============================] - 1s 167us/step - loss: 1.5757 - accuracy: 0.3649 - recall: 0.0877 - val_loss: 1.4832 - val_accuracy: 0.4128 - val_recall: 0.0878\n",
      "Epoch 123/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5763 - accuracy: 0.3781 - recall: 0.0878 - val_loss: 1.4746 - val_accuracy: 0.4096 - val_recall: 0.0879\n",
      "Epoch 124/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5698 - accuracy: 0.3740 - recall: 0.0880 - val_loss: 1.4725 - val_accuracy: 0.4148 - val_recall: 0.0881\n",
      "Epoch 125/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5725 - accuracy: 0.3701 - recall: 0.0882 - val_loss: 1.4704 - val_accuracy: 0.4076 - val_recall: 0.0882\n",
      "Epoch 126/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5679 - accuracy: 0.3737 - recall: 0.0883 - val_loss: 1.5010 - val_accuracy: 0.4116 - val_recall: 0.0883\n",
      "Epoch 127/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5736 - accuracy: 0.3772 - recall: 0.0884 - val_loss: 1.4677 - val_accuracy: 0.4016 - val_recall: 0.0885\n",
      "Epoch 128/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5683 - accuracy: 0.3719 - recall: 0.0885 - val_loss: 1.5003 - val_accuracy: 0.4108 - val_recall: 0.0886\n",
      "Epoch 129/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5682 - accuracy: 0.3748 - recall: 0.0887 - val_loss: 1.4686 - val_accuracy: 0.4192 - val_recall: 0.0888\n",
      "Epoch 130/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5764 - accuracy: 0.3729 - recall: 0.0888 - val_loss: 1.4722 - val_accuracy: 0.4096 - val_recall: 0.0889\n",
      "Epoch 131/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5748 - accuracy: 0.3753 - recall: 0.0890 - val_loss: 1.4914 - val_accuracy: 0.4108 - val_recall: 0.0890\n",
      "Epoch 132/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5647 - accuracy: 0.3737 - recall: 0.0891 - val_loss: 1.4819 - val_accuracy: 0.4164 - val_recall: 0.0892\n",
      "Epoch 133/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5739 - accuracy: 0.3716 - recall: 0.0893 - val_loss: 1.4795 - val_accuracy: 0.4160 - val_recall: 0.0894\n",
      "Epoch 134/200\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.5721 - accuracy: 0.3732 - recall: 0.0894 - val_loss: 1.4834 - val_accuracy: 0.4112 - val_recall: 0.0895\n",
      "Epoch 135/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5677 - accuracy: 0.3739 - recall: 0.0895 - val_loss: 1.4682 - val_accuracy: 0.4228 - val_recall: 0.0896\n",
      "Epoch 136/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5709 - accuracy: 0.3677 - recall: 0.0896 - val_loss: 1.4939 - val_accuracy: 0.3968 - val_recall: 0.0897\n",
      "Epoch 137/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5650 - accuracy: 0.3796 - recall: 0.0897 - val_loss: 1.4863 - val_accuracy: 0.4184 - val_recall: 0.0897\n",
      "Epoch 138/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5738 - accuracy: 0.3685 - recall: 0.0898 - val_loss: 1.4916 - val_accuracy: 0.4196 - val_recall: 0.0898\n",
      "Epoch 139/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5562 - accuracy: 0.3788 - recall: 0.0898 - val_loss: 1.4630 - val_accuracy: 0.4196 - val_recall: 0.0899\n",
      "Epoch 140/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5659 - accuracy: 0.3733 - recall: 0.0900 - val_loss: 1.4782 - val_accuracy: 0.4256 - val_recall: 0.0900\n",
      "Epoch 141/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5789 - accuracy: 0.3693 - recall: 0.0900 - val_loss: 1.4789 - val_accuracy: 0.4136 - val_recall: 0.0901\n",
      "Epoch 142/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5696 - accuracy: 0.3773 - recall: 0.0901 - val_loss: 1.4794 - val_accuracy: 0.4200 - val_recall: 0.0902\n",
      "Epoch 143/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5633 - accuracy: 0.3809 - recall: 0.0903 - val_loss: 1.4733 - val_accuracy: 0.4168 - val_recall: 0.0904\n",
      "Epoch 144/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5596 - accuracy: 0.3744 - recall: 0.0904 - val_loss: 1.4860 - val_accuracy: 0.4068 - val_recall: 0.0905\n",
      "Epoch 145/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5692 - accuracy: 0.3767 - recall: 0.0906 - val_loss: 1.4427 - val_accuracy: 0.4356 - val_recall: 0.0907\n",
      "Epoch 146/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5668 - accuracy: 0.3811 - recall: 0.0907 - val_loss: 1.4741 - val_accuracy: 0.4108 - val_recall: 0.0908\n",
      "Epoch 147/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5567 - accuracy: 0.3779 - recall: 0.0908 - val_loss: 1.4685 - val_accuracy: 0.4204 - val_recall: 0.0909\n",
      "Epoch 148/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5572 - accuracy: 0.3797 - recall: 0.0909 - val_loss: 1.4700 - val_accuracy: 0.4268 - val_recall: 0.0910\n",
      "Epoch 149/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5725 - accuracy: 0.3767 - recall: 0.0911 - val_loss: 1.4730 - val_accuracy: 0.4256 - val_recall: 0.0911\n",
      "Epoch 150/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5623 - accuracy: 0.3751 - recall: 0.0911 - val_loss: 1.4690 - val_accuracy: 0.4140 - val_recall: 0.0912\n",
      "Epoch 151/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5588 - accuracy: 0.3765 - recall: 0.0912 - val_loss: 1.4690 - val_accuracy: 0.4196 - val_recall: 0.0913\n",
      "Epoch 152/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5676 - accuracy: 0.3779 - recall: 0.0913 - val_loss: 1.4778 - val_accuracy: 0.4032 - val_recall: 0.0913\n",
      "Epoch 153/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5611 - accuracy: 0.3741 - recall: 0.0914 - val_loss: 1.4732 - val_accuracy: 0.4264 - val_recall: 0.0914\n",
      "Epoch 154/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5566 - accuracy: 0.3776 - recall: 0.0914 - val_loss: 1.4548 - val_accuracy: 0.4264 - val_recall: 0.0915\n",
      "Epoch 155/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5561 - accuracy: 0.3763 - recall: 0.0915 - val_loss: 1.4404 - val_accuracy: 0.4236 - val_recall: 0.0916\n",
      "Epoch 156/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5579 - accuracy: 0.3784 - recall: 0.0917 - val_loss: 1.4672 - val_accuracy: 0.4316 - val_recall: 0.0918\n",
      "Epoch 157/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5658 - accuracy: 0.3745 - recall: 0.0918 - val_loss: 1.4513 - val_accuracy: 0.4388 - val_recall: 0.0919\n",
      "Epoch 158/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5667 - accuracy: 0.3712 - recall: 0.0920 - val_loss: 1.4864 - val_accuracy: 0.4228 - val_recall: 0.0920\n",
      "Epoch 159/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5649 - accuracy: 0.3721 - recall: 0.0920 - val_loss: 1.4521 - val_accuracy: 0.4156 - val_recall: 0.0921\n",
      "Epoch 160/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5548 - accuracy: 0.3828 - recall: 0.0921 - val_loss: 1.4773 - val_accuracy: 0.4200 - val_recall: 0.0922\n",
      "Epoch 161/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5543 - accuracy: 0.3728 - recall: 0.0923 - val_loss: 1.4963 - val_accuracy: 0.4020 - val_recall: 0.0923\n",
      "Epoch 162/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5585 - accuracy: 0.3717 - recall: 0.0923 - val_loss: 1.4741 - val_accuracy: 0.4196 - val_recall: 0.0924\n",
      "Epoch 163/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5586 - accuracy: 0.3777 - recall: 0.0924 - val_loss: 1.4613 - val_accuracy: 0.4228 - val_recall: 0.0925\n",
      "Epoch 164/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5659 - accuracy: 0.3773 - recall: 0.0925 - val_loss: 1.4561 - val_accuracy: 0.4212 - val_recall: 0.0926\n",
      "Epoch 165/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5561 - accuracy: 0.3756 - recall: 0.0926 - val_loss: 1.4506 - val_accuracy: 0.4216 - val_recall: 0.0927\n",
      "Epoch 166/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5575 - accuracy: 0.3747 - recall: 0.0927 - val_loss: 1.4502 - val_accuracy: 0.4256 - val_recall: 0.0928\n",
      "Epoch 167/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5569 - accuracy: 0.3785 - recall: 0.0928 - val_loss: 1.5019 - val_accuracy: 0.4084 - val_recall: 0.0929\n",
      "Epoch 168/200\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.5565 - accuracy: 0.3759 - recall: 0.0929 - val_loss: 1.4808 - val_accuracy: 0.4168 - val_recall: 0.0929\n",
      "Epoch 169/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5625 - accuracy: 0.3773 - recall: 0.0930 - val_loss: 1.4570 - val_accuracy: 0.4244 - val_recall: 0.0930\n",
      "Epoch 170/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5542 - accuracy: 0.3827 - recall: 0.0931 - val_loss: 1.4751 - val_accuracy: 0.4156 - val_recall: 0.0931\n",
      "Epoch 171/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5566 - accuracy: 0.3760 - recall: 0.0931 - val_loss: 1.4703 - val_accuracy: 0.4276 - val_recall: 0.0931\n",
      "Epoch 172/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5565 - accuracy: 0.3824 - recall: 0.0932 - val_loss: 1.4420 - val_accuracy: 0.4208 - val_recall: 0.0932\n",
      "Epoch 173/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5648 - accuracy: 0.3725 - recall: 0.0933 - val_loss: 1.4866 - val_accuracy: 0.4120 - val_recall: 0.0933\n",
      "Epoch 174/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5530 - accuracy: 0.3817 - recall: 0.0933 - val_loss: 1.4559 - val_accuracy: 0.4200 - val_recall: 0.0933\n",
      "Epoch 175/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5509 - accuracy: 0.3787 - recall: 0.0934 - val_loss: 1.4584 - val_accuracy: 0.4212 - val_recall: 0.0934\n",
      "Epoch 176/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5611 - accuracy: 0.3815 - recall: 0.0935 - val_loss: 1.4810 - val_accuracy: 0.4124 - val_recall: 0.0935\n",
      "Epoch 177/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5518 - accuracy: 0.3796 - recall: 0.0935 - val_loss: 1.4573 - val_accuracy: 0.4256 - val_recall: 0.0936\n",
      "Epoch 178/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5471 - accuracy: 0.3817 - recall: 0.0936 - val_loss: 1.4438 - val_accuracy: 0.4224 - val_recall: 0.0937\n",
      "Epoch 179/200\n",
      "7500/7500 [==============================] - 1s 169us/step - loss: 1.5575 - accuracy: 0.3797 - recall: 0.0937 - val_loss: 1.4622 - val_accuracy: 0.4224 - val_recall: 0.0938\n",
      "Epoch 180/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5479 - accuracy: 0.3860 - recall: 0.0938 - val_loss: 1.4561 - val_accuracy: 0.4248 - val_recall: 0.0938\n",
      "Epoch 181/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5445 - accuracy: 0.3867 - recall: 0.0939 - val_loss: 1.4577 - val_accuracy: 0.4332 - val_recall: 0.0939\n",
      "Epoch 182/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5494 - accuracy: 0.3747 - recall: 0.0939 - val_loss: 1.4693 - val_accuracy: 0.4200 - val_recall: 0.0940\n",
      "Epoch 183/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5553 - accuracy: 0.3799 - recall: 0.0940 - val_loss: 1.4855 - val_accuracy: 0.4152 - val_recall: 0.0940\n",
      "Epoch 184/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5528 - accuracy: 0.3831 - recall: 0.0940 - val_loss: 1.4532 - val_accuracy: 0.4164 - val_recall: 0.0940\n",
      "Epoch 185/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5564 - accuracy: 0.3828 - recall: 0.0941 - val_loss: 1.4480 - val_accuracy: 0.4272 - val_recall: 0.0941\n",
      "Epoch 186/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5497 - accuracy: 0.3771 - recall: 0.0942 - val_loss: 1.4462 - val_accuracy: 0.4368 - val_recall: 0.0942\n",
      "Epoch 187/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5560 - accuracy: 0.3807 - recall: 0.0942 - val_loss: 1.4515 - val_accuracy: 0.4252 - val_recall: 0.0943\n",
      "Epoch 188/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5590 - accuracy: 0.3748 - recall: 0.0943 - val_loss: 1.4482 - val_accuracy: 0.4156 - val_recall: 0.0943\n",
      "Epoch 189/200\n",
      "7500/7500 [==============================] - 1s 173us/step - loss: 1.5504 - accuracy: 0.3731 - recall: 0.0944 - val_loss: 1.4516 - val_accuracy: 0.4176 - val_recall: 0.0944\n",
      "Epoch 190/200\n",
      "7500/7500 [==============================] - 1s 175us/step - loss: 1.5463 - accuracy: 0.3844 - recall: 0.0945 - val_loss: 1.4612 - val_accuracy: 0.4236 - val_recall: 0.0945\n",
      "Epoch 191/200\n",
      "7500/7500 [==============================] - 1s 176us/step - loss: 1.5539 - accuracy: 0.3893 - recall: 0.0946 - val_loss: 1.4540 - val_accuracy: 0.4360 - val_recall: 0.0946\n",
      "Epoch 192/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5552 - accuracy: 0.3808 - recall: 0.0947 - val_loss: 1.4820 - val_accuracy: 0.4272 - val_recall: 0.0947\n",
      "Epoch 193/200\n",
      "7500/7500 [==============================] - 1s 174us/step - loss: 1.5603 - accuracy: 0.3801 - recall: 0.0947 - val_loss: 1.4665 - val_accuracy: 0.4204 - val_recall: 0.0947\n",
      "Epoch 194/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5571 - accuracy: 0.3747 - recall: 0.0947 - val_loss: 1.4817 - val_accuracy: 0.4164 - val_recall: 0.0947\n",
      "Epoch 195/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5527 - accuracy: 0.3759 - recall: 0.0947 - val_loss: 1.4562 - val_accuracy: 0.4148 - val_recall: 0.0948\n",
      "Epoch 196/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5423 - accuracy: 0.3755 - recall: 0.0948 - val_loss: 1.4568 - val_accuracy: 0.4244 - val_recall: 0.0948\n",
      "Epoch 197/200\n",
      "7500/7500 [==============================] - 1s 170us/step - loss: 1.5348 - accuracy: 0.3849 - recall: 0.0949 - val_loss: 1.4587 - val_accuracy: 0.4156 - val_recall: 0.0949\n",
      "Epoch 198/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5527 - accuracy: 0.3841 - recall: 0.0949 - val_loss: 1.4729 - val_accuracy: 0.4076 - val_recall: 0.0950\n",
      "Epoch 199/200\n",
      "7500/7500 [==============================] - 1s 172us/step - loss: 1.5461 - accuracy: 0.3815 - recall: 0.0950 - val_loss: 1.4741 - val_accuracy: 0.4100 - val_recall: 0.0950\n",
      "Epoch 200/200\n",
      "7500/7500 [==============================] - 1s 171us/step - loss: 1.5519 - accuracy: 0.3801 - recall: 0.0950 - val_loss: 1.4481 - val_accuracy: 0.4284 - val_recall: 0.0951\n",
      "model trained\n"
     ]
    }
   ],
   "source": [
    "# create our MLP and then compile the model using mean absolute\n",
    "# percentage error as our loss, implying that we seek to minimize\n",
    "# the absolute percentage difference between our price *predictions*\n",
    "# and the *actual prices*\n",
    "model = models.create_cnn(trainX.shape[1])\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "set_epsilon(1)\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics = ['accuracy', tf.keras.metrics.Recall()])\n",
    " \n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "    epochs=200, batch_size=20)\n",
    "\n",
    "print('model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] predicting house prices...\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing data\n",
    "print(\"[INFO] predicting galaxy star masses...\")\n",
    "preds = model.predict(testX)\n",
    "\n",
    "# compute the difference between the *predicted* central galaxy star mass and the\n",
    "# *actual* mass, then compute the percentage difference and\n",
    "# the absolute percentage difference\n",
    "\n",
    "\n",
    "diff = preds - testY\n",
    "#percentDiff = (diff / testY) * 100\n",
    "#absPercentDiff = np.abs(np.array(percentDiff))\n",
    " \n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "#mean = np.mean(absPercentDiff)\n",
    "#std = np.std(absPercentDiff)\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4616\n"
     ]
    }
   ],
   "source": [
    "diffs = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    diffs.append(preds[i].argmax() - testY[i].argmax())\n",
    "    #print ('%d, %d'%(preds[i].argmax(), testY[i].argmax()))\n",
    "diffs= np.array(diffs)\n",
    "\n",
    "print((len(diffs) - np.count_nonzero(diffs))/len(diffs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['val_recall'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
